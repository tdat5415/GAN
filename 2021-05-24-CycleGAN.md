---
layout: post
title:  "CycleGAN"
date:   2021-05-24
excerpt: "CycleGAN 맛보기"
tag:
- GAN
- CNN
- cyclegan
comments: true
---

pix2pix는 모델이 생성자, 판별자 이렇게 2개인대 비해

cyclegan은 모델이 생성자2개, 판별자2개 이렇게 4개이다.

![cyclegan](https://user-images.githubusercontent.com/48349693/119339108-c38b4780-bccb-11eb-9ec5-3cde9f499e8c.PNG)

위의 그림으로 원리를 설명하면

일단 to_zebra gen이 학습이 될려면 3가지의 loss를 받아야한다.

첫번째로 A1이 to_zebra gen에 들어가 A3을 만들어내고 그것이 is_zebra disc에 들어간다. 

이의 결과값과 All 1s와의 차이가 첫번째 loss가 된다.

두번째는 A1이 to_zebra gen에 들어가 A3을 만들어냈는데 그것이 또 다른곳에 들어간다. 

위 그림에는 안적었는데 A2 왼쪽에 곡선 화살표도 generated zebra(A3) 이다.

A3이 to_horse gen에 들어가서 A2를 만들어낸다. 

A2가 cycled horse 라고 이 이미지와 input horse(A1)와의 차이가 두번째 loss가 된다.

세번재는 horse를 넣어서 zebra를 만들어내는 생성자에 input zebra를 넣는데

결국은 zebra가 나오겠지만 이를 same zebra라고 하고

same zebra와 input zebra와의 차이가 세번째 loss가 된다.

세가지의 loss들의 가중치는 따로 정해줘야한다.

zebra 생성자가 이렇게

horse 생성자도 

---

---

### 모듈 불러오기

```python
!pip install -q git+https://github.com/tensorflow/examples.git

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow_examples.models.pix2pix import pix2pix
import os
import time
import matplotlib.pyplot as plt
from IPython.display import clear_output

tfds.disable_progress_bar()
AUTOTUNE = tf.data.experimental.AUTOTUNE
```

### 데이터 가져오기

```python
dataset, metadata = tfds.load('cycle_gan/horse2zebra', with_info=True, as_supervised=True)
train_horses, train_zebras = dataset['trainA'], dataset['trainB']
test_horses, test_zebras = dataset['testA'], dataset['testB']
```

 ### 상수
 
 ```python
BUFFER_SIZE = 1000
BATCH_SIZE = 1
IMG_WIDTH = 256
IMG_HEIGHT = 256
 ```
 
 ### 전처리 함수 정의
 
 ```python
def normalize(image): # [-1, 1]
    image = tf.cast(image, tf.float32)
    image = (image / 127.5) - 1
    return image

def random_jitter(image):
    image = tf.image.resize(image, [286,286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])
    image = tf.image.random_flip_left_right(image)
    return image

def preprocess_image_train(image, label):
    image = random_jitter(image)
    image = normalize(image)
    return image

def preprocess_image_test(image, label):
    image = normalize(image)
    return image
```

### 전처리 파이프라인

```python
train_horses = train_horses.map(preprocess_image_train, num_parallel_calls=AUTOTUNE)
train_horses = train_horses.cache().shuffle(BUFFER_SIZE).batch(1)

train_zebras = train_zebras.map(preprocess_image_train, num_parallel_calls=AUTOTUNE)
train_zebras = train_zebras.cache().shuffle(BUFFER_SIZE).batch(1)

test_horses = test_horses.map(preprocess_image_test, num_parallel_calls=AUTOTUNE)
test_horses = test_horses.cache().shuffle(BUFFER_SIZE).batch(1)

test_zebras = test_zebras.map(preprocess_image_test, num_parallel_calls=AUTOTUNE)
test_zebras = test_zebras.cache().shuffle(BUFFER_SIZE).batch(1)
```

### 이미지 전처리 테스트

```python
sample_horse = next(iter(train_horses))
sample_zebra = next(iter(train_zebras))

plt.figure(figsize=(15,40))

plt.subplot(141)
plt.title('Horse')
plt.imshow(sample_horse[0] * 0.5 + 0.5)

plt.subplot(142)
plt.title('Horse with random jitter')
plt.imshow(random_jitter(sample_horse[0]) * 0.5 + 0.5)

plt.subplot(143)
plt.title('Zebra')
plt.imshow(sample_zebra[0] * 0.5 + 0.5)

plt.subplot(144)
plt.title('Zebra with random jitter')
plt.imshow(random_jitter(sample_zebra[0]) * 0.5 + 0.5)
```

![jiiter test](https://user-images.githubusercontent.com/48349693/119351301-4cf64600-bcdb-11eb-86da-286b18fcdd5e.PNG)

### 모델 가져오기

```python
OUTPUT_CHANNELS = 3

G_to_zebra = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')
G_to_horse = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')

D_horse = pix2pix.discriminator(norm_type='instancenorm', target=False)
D_zebra = pix2pix.discriminator(norm_type='instancenorm', target=False)
```

### 생성자 모델 테스트

```python
to_zebra = G_to_zebra(sample_horse)
to_horse = G_to_horse(sample_zebra)

plt.figure(figsize=(8,8))

plt.subplot(221)
plt.title('Horse')
plt.imshow(sample_horse[0] * 0.5 + 0.5)

plt.subplot(222)
plt.title('To Zebra')
plt.imshow(to_zebra[0] * 0.5 + 0.5)

plt.subplot(223)
plt.title('Zebra')
plt.imshow(sample_zebra[0] * 0.5 + 0.5)

plt.subplot(224)
plt.title('To Horse')
plt.imshow(to_horse[0] * 0.5 + 0.5)
```

![gen test](https://user-images.githubusercontent.com/48349693/119351317-51226380-bcdb-11eb-9f84-92a661ae8cc9.PNG)

### 판별자 모델 테스트

```python
plt.figure(figsize=(8,8))

plt.subplot(121)
plt.title('Is a real zebra?')
plt.imshow(D_zebra(sample_zebra)[0,...,-1], cmap='RdBu_r')

plt.subplot(122)
plt.title('Is a real horse?')
plt.imshow(D_horse(sample_horse)[0,...,-1], cmap='RdBu_r')
```

![disc test](https://user-images.githubusercontent.com/48349693/119351329-541d5400-bcdb-11eb-9295-0897744588e5.PNG)

### loss 함수 정의

```python
LAMBDA = 10

loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True) # no softmax

def discriminator_loss(real, generated):
    real_loss       = loss_obj(tf.ones_like(real), real)
    generated_loss  = loss_obj(tf.zeros_like(generated), generated)
    total_disc_loss = real_loss + generated_loss
    return total_disc_loss * 0.5

def generator_loss(generated):
    return loss_obj(tf.ones_like(generated), generated)

def calc_cycle_loss(real_image, cycled_image):
    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))
    return LAMBDA * loss

def identity_loss(real_image, same_image):
    loss = tf.reduce_mean(tf.abs(real_image - same_image))
    return LAMBDA * 0.5 * loss
```

### 옵티마이저 정의

```python
G_to_zebra_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
G_to_horse_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

D_horse_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
D_zebra_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
```

### 체크포인트 정의

```python
checkpoint_path = './checkpoints/train'
ckpt = tf.train.Checkpoint(G_to_zebra=G_to_zebra,
                           G_to_horse=G_to_horse,
                           D_horse=D_horse,
                           D_zebra=D_zebra,
                           G_to_zebra_optimizer=G_to_zebra_optimizer,
                           G_to_horse_optimizer=G_to_horse_optimizer,
                           D_horse_optimizer=D_horse_optimizer,
                           D_zebra_optimizer=D_zebra_optimizer)

ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)

if ckpt_manager.latest_checkpoint:
    ckpt.restore(ckpt_manager.latest_checkpoint)
    print('Latest checkpoint restored')
```

### gradient one step

```python
@tf.function
def train_step(real_horse, real_zebra): # horse, zebra
    # with tf.GradientTape(persistent = True) as tape: # tape이 반복사용될때 True
    with tf.GradientTape() as G_tape1, tf.GradientTape() as G_tape2, tf.GradientTape() as D_tape1, tf.GradientTape() as D_tape2:
        fake_zebra = G_to_zebra(real_horse, training=True)
        fake_horse = G_to_horse(real_zebra, training=True)
        cycled_horse = G_to_horse(fake_zebra, training=True)
        cycled_zebra = G_to_zebra(fake_horse, training=True)
        same_zebra = G_to_zebra(real_zebra, training=True)
        same_horse = G_to_horse(real_horse, training=True)

        disc_real_horse = D_horse(real_horse, training=True)
        disc_real_zebra = D_zebra(real_zebra, training=True)
        disc_fake_horse = D_horse(fake_horse, training=True)
        disc_fake_zebra = D_zebra(fake_zebra, training=True)


        gen_horse_loss = generator_loss(disc_fake_horse)
        gen_zebra_loss = generator_loss(disc_fake_zebra)

        total_cycle_loss = calc_cycle_loss(real_horse, cycled_horse) + calc_cycle_loss(real_zebra, cycled_zebra)

        total_gen_horse_loss = gen_horse_loss + total_cycle_loss + identity_loss(real_horse, same_horse)
        total_gen_zebra_loss = gen_zebra_loss + total_cycle_loss + identity_loss(real_zebra, same_zebra)

        disc_horse_loss = discriminator_loss(disc_real_horse, disc_fake_horse)
        disc_zebra_loss = discriminator_loss(disc_real_zebra, disc_fake_zebra)
        

        G_to_horse_grad = G_tape1.gradient(total_gen_horse_loss, G_to_horse.trainable_variables)
        G_to_zebra_grad = G_tape2.gradient(total_gen_zebra_loss, G_to_zebra.trainable_variables)
        D_horse_grad = D_tape1.gradient(disc_horse_loss, D_horse.trainable_variables)
        D_zebra_grad = D_tape2.gradient(disc_zebra_loss, D_zebra.trainable_variables)

        G_to_horse_optimizer.apply_gradients(zip(G_to_horse_grad, G_to_horse.trainable_variables))
        G_to_zebra_optimizer.apply_gradients(zip(G_to_zebra_grad, G_to_zebra.trainable_variables))
        D_horse_optimizer.apply_gradients(zip(D_horse_grad, D_horse.trainable_variables))
        D_zebra_optimizer.apply_gradients(zip(D_zebra_grad, D_zebra.trainable_variables))
```

total_cycle_loss를 생성자 두개가 공통으로 사용하는것을 알 수 있다.

그리고 identity_loss는 zebra 생성자에 zebra 넣고 zebra가 나오냐는 그런 식이다.

판별자 loss는 pix2pix때와 같다.

### 학습하기

```python
EPOCHS = 40

def generate_image(model, test_input):
    prediction = model(test_input)
    
    plt.figure(figsize=(12,12))

    plt.subplot(121)
    plt.title('Input Image')
    plt.imshow(test_input[0] * 0.5 + 0.5)
    plt.axis('off')

    plt.subplot(122)
    plt.title('Predicted Image')
    plt.imshow(prediction[0] * 0.5 + 0.5)
    plt.axis('off')

    plt.show()

for epoch in range(EPOCHS):
    start = time.time()

    n = 0
    for image_x, image_y in tf.data.Dataset.zip((train_horses, train_zebras)):
        train_step(image_x, image_y)
        if n % 10 == 0:
            print('.', end='')
        n += 1

    clear_output(wait=True)
    generate_image(G_to_zebra, sample_horse)

    if (epoch + 1) % 5 == 0:
        ckpt_save_path = ckpt_manager.save()
        print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, ckpt_save_path))
    print('Time taken for epoch {} is {} sec\n'.format(epoch + 1, time.time() - start))
```

![train](https://user-images.githubusercontent.com/48349693/119354016-87adad80-bcde-11eb-9a2a-3384383a5688.PNG)

코랩 gpu 썼는데도 1epoch에 상당한 오랜 시간이 걸렸다..

논문에서는 200 epoch은 해야 괜찮은 결과가 나온다고한다. 

물론 모델자체가 다르다.

```python
# Run the trained model on the test dataset
for inp in test_horses.take(5):
  generate_image(G_to_zebra, inp)
```

![test](https://user-images.githubusercontent.com/48349693/119354926-96e12b00-bcdf-11eb-95e9-d824fdea2cee.PNG)

7epoch 후의 테스트 결과이다.

---

---

참고 URL : <https://www.tensorflow.org/tutorials/generative/cyclegan?hl=ko>

