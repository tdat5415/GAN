---
layout: post
title:  "Pix2Pix"
date:   2021-05-20
excerpt: "Pix2Pix 맛보기"
tag:
- GAN
- CNN
- Pix2Pix
comments: true
---

![example](https://user-images.githubusercontent.com/48349693/118951869-696e4780-b996-11eb-936e-2ae931b4fbb6.PNG)

이전 포스트와 달리 이번에는 입력으로 이미지가 들어갑니다.

위의 그림처럼 입력으로 첫번째 이미지를 주면 세번째 이미지로 출력됩니다.

가운데 이미지는 실제 이미지입니다.

즉, 생성자가 이미지 to 이미지 입니다.

---

---

![gen_model](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gen.png?raw=1)

위의 그림은 생성자가 gradient를 받기위한 과정입니다.

여기서 target image는 실제 이미지

input image는 이상한 컬러풀한 네모네모 이미지

```python
LAMBDA = 100

loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(disc_generated_output, gen_output, target):
  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)

  # mean absolute error
  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))

  total_gen_loss = gan_loss + (LAMBDA * l1_loss)

  return total_gen_loss, gan_loss, l1_loss
```

위 코드에서 특이한것은 이전 포스트의 생성자손실함수와는 다르게 

생성자의 입력이미지와 출력이미지의 MAE까지도 loss로 넣습니다.

즉,

* 판별자로부터의 loss
* 입력과 출력의 MAE

두 개를 생성자의 loss로 갖습니다.

둘중 하나만 loss로 가지면 어떻게 되나 궁금해서 테스트해보았습니다.

![total_loss_epoch_10](https://user-images.githubusercontent.com/48349693/118954179-78ee9000-b998-11eb-8a47-fde53e04ec7a.PNG)

↑ epoch10 (total_gen_loss로 gradient를 구한후 적용)

![l1loss_epoch_13](https://user-images.githubusercontent.com/48349693/118954197-7c821700-b998-11eb-9a4d-ee2bbb4e1d54.PNG)

↑ epoch13 (l1_loss로 gradient를 구한후 적용)

![gan_loss_epoch_10](https://user-images.githubusercontent.com/48349693/118954211-80159e00-b998-11eb-955a-d5eab36f29cb.PNG)

↑ epoch10 (gan_loss로 gradient를 구한후 적용)

l1_loss는 생성자 모델만으로 구한 loss입니다.

그럼에도 꽤 나쁘진 않지만 안개낀듯 흐릿한 이미지입니다.

gan_loss를 포함해야 이미지가 선명해지는 느낌입니다.

---

---

![disc_model](https://www.tensorflow.org/tutorials/generative/pix2pix_files/output_YHoUui4om-Ev_0.png?hl=ko)

위 그림은 판별자의 모델입니다.

특이하게 입력을 두개를 받고 출력을 30x30으로 합니다.

입력으로 네모네모이미지와 실제 이미지(또는 생성된이미지)를 받습니다.

네모네모이미지, 실제이미지 쌍은 라벨로 전부 1인 30x30을 받고

네모네모이미지, 생성된이미지 쌍은 라벨로 전부 0인 30x30을 받으며 학습됩니다.

```python
loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(disc_real_output, disc_generated_output):
  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)

  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)

  total_disc_loss = real_loss + generated_loss

  return total_disc_loss
```

판별자의 손실함수입니다.

이전 포스트의 판별자 손실함수와 구조가 같습니다.

![disc_model](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/dis.png?raw=1)

---

---

```python
@tf.function
def train_step(input_image, target, epoch):
  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    gen_output = generator(input_image, training=True)

    disc_real_output = discriminator([input_image, target], training=True)
    disc_generated_output = discriminator([input_image, gen_output], training=True)

    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)
    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)

  generator_gradients = gen_tape.gradient(gen_total_loss,
                                          generator.trainable_variables)
  discriminator_gradients = disc_tape.gradient(disc_loss,
                                               discriminator.trainable_variables)

  generator_optimizer.apply_gradients(zip(generator_gradients,
                                          generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,
                                              discriminator.trainable_variables))

  with summary_writer.as_default():
    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)
    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)
    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)
    tf.summary.scalar('disc_loss', disc_loss, step=epoch)
```

1. 이미지 생성
2. 판별
3. loss 구하기
4. grad 구하기
5. 적용

---

---

참고URL : <https://www.tensorflow.org/tutorials/generative/pix2pix?hl=ko>








