---
layout: post
title:  "생성적 적대 신경망 GAN"
date:   2021-05-19
excerpt: "GAN이란? & 필기체 숫자 같은 이미지 만들어 보기"
tag:
- GAN
- CNN
comments: true
---

### GAN 이란?

두 개의 신경망이 서로 라이벌 관계에 있으며 경쟁하며 같이 성장한다.

한 신경망은 이미지를 생성, 다른 하나는 그 이미지가 올바른지 판별한다.

생성자는 판별자로부터 더 좋은 이미지를 생성하도록 피드백을 받고

판별자는 이미지가 생성자의 이미지인지 원래 자기가 가지고 있던 이미지(train data)인지를 구별하여 스스로 피드백 받는다.


### 한번 만들어보자

일단 필요한 것들

```python
import tensorflow as tf
import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import PIL
from tensorflow.keras import layers
import time
import os
from IPython import display
```

---

mnist 다운로드후 셔플 & 배치로 나누기

```python
(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()
train_images = train_images.reshape(-1, 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5
BUFFER_SIZE = 60000
BATCH_SIZE = 256
train_dataset = tf.data.Dataset.from_tensor_slices(train_images)
train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
```

---

생성자모델이다.

shape=(100,)짜리 넣으면 shape(28,28,1)짜리 흑백이미지가 나온다.

```python
def make_generator_model():
  model = tf.keras.Sequential()
  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU())

  model.add(layers.Reshape((7, 7, 256)))
  assert model.output_shape == (None, 7, 7, 256)

  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
  assert model.output_shape == (None, 7, 7, 128)
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU())
  
  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
  assert model.output_shape == (None, 14, 14, 64)
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU())

  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
  assert model.output_shape == (None, 28, 28, 1)

  return model
```

---

테스트

```python
generator = make_generator_model()
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
plt.imshow(generated_image[0, :, :, 0], cmap='gray')
```
![test1](https://user-images.githubusercontent.com/48349693/118804745-0ae69200-b8e0-11eb-9f4e-c04092cfc99b.PNG)

---

판별자모델이다.

이미지가 들어오면 이것이 mnist같은 이미지인지 아닌지 판별한다.

```python
def make_discriminator_model():
  model = tf.keras.Sequential()
  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(28,28,1)))
  model.add(layers.LeakyReLU())
  model.add(layers.Dropout(0.3))

  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
  model.add(layers.LeakyReLU())
  model.add(layers.Dropout(0.3))

  model.add(layers.Flatten())
  model.add(layers.Dense(1))

  return model  
```

---

테스트

```python
discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
```
tf.Tensor([[0.00175558]], shape=(1, 1), dtype=float32)

---

loss 함수 정의

여기서 fake_output은 판별자는 0을 목표로 생성자는 1을 목표로 한다.

```python
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True) # softmax 썼으면 False, 아니면 True

def discriminator_loss(real_output, fake_output):
  real_loss = cross_entropy(tf.ones_like(real_output), real_output)
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
  total_loss = real_loss + fake_loss
  return total_loss

def generator_loss(fake_output):
  return cross_entropy(tf.ones_like(fake_output), fake_output)
```

---

옵티마이저는 따로 정의해준다.

그외 모델저장하는 체크포인트

테스트용 인풋값을 정의해준다.

```python
gen_optimizer = tf.keras.optimizers.Adam(1e-4)
disc_optimizer = tf.keras.optimizers.Adam(1e-4)

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(gen_optimizer=gen_optimizer,
                                 disc_optimizer=disc_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)
                                 
EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16

# 이 시드를 시간이 지나도 재활용하겠습니다. 
# (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문입니다.) 
seed = tf.random.normal([num_examples_to_generate, noise_dim])
```

---

@tf.function이 함수를 컴파일해두어서 호출할때마다 빠르게 실행할 수 있나보다.
이 함수가 한번 실행될때마다 한번 gradients가 적용된다.

```python
@tf.function
def train_step(images):
  noise = tf.random.normal([BATCH_SIZE, noise_dim]) # (256, 100)

  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    generated_images = generator(noise, training=True)

    real_output = discriminator(images, training=True)
    fake_output = discriminator(generated_images, training=True)

    gen_loss = generator_loss(fake_output)
    disc_loss = discriminator_loss(real_output, fake_output)
  
    grad_of_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)
    grad_of_disc = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    gen_optimizer.apply_gradients(zip(grad_of_gen, generator.trainable_variables))
    disc_optimizer.apply_gradients(zip(grad_of_disc, discriminator.trainable_variables))
```

---

epochs만큼 생성자모델과 판별자모델을 학습시킨다.

학습하면서 테스트용seed를 이용하여 이미지를 실시간 출력시킨다.

```python
def train(dataset, epochs):
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)

    display.clear_output(wait=True)
    generate_and_save_images(generator, epoch+1, seed)

    if (epoch+1) % 15 == 0:
      checkpoint.save(file_prefix=checkpoint_prefix)
    
    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  display.clear_output(wait=True)
  generate_and_save_images(generator, epoch+1, seed)
  
def generate_and_save_images(model, epoch, test_input):
  predictions = model(test_input, training=False)

  fig = plt.figure(figsize=(4,4))
  for i in range(predictions.shape[0]):
    plt.subplot(4, 4, i+1)
    plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
    plt.axis('off')

  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
  plt.show() 
```

---

50번 학습후 생성자가 테스트용seed로 출력한 이미지들

![16](https://user-images.githubusercontent.com/48349693/118807431-433b9f80-b8e3-11eb-94ba-c660ac4f674f.PNG)

![dcgan](https://user-images.githubusercontent.com/48349693/118807530-65352200-b8e3-11eb-9608-1b35d18c6927.gif)

---

참고URL : <https://www.tensorflow.org/tutorials/generative/dcgan?hl=ko>
